{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "RPINqgyq9zbB",
        "NbK098GK_mDp",
        "kWf7VF5S99iW",
        "XEK-nx2iM9DC",
        "L1SjLQKWu-eR",
        "8FzwJGP4n18o",
        "Dm2_YMcrn9Wh",
        "3WAh8U2Gs5Nw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPINqgyq9zbB",
        "colab_type": "text"
      },
      "source": [
        "<H1>  Install and Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SGmmyG7-y2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive\n",
        "!pip install JSAnimation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odqgH1KIMSdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image as Im\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import h5py\n",
        "import random\n",
        "from tensorflow.keras.layers import SpatialDropout2D, Conv2D, MaxPooling2D, TimeDistributed, Bidirectional, LSTM\n",
        "from tensorflow.keras.layers import Input, LeakyReLU, Add, SpatialDropout3D,Conv3D, MaxPooling3D, Activation, BatchNormalization, PReLU,concatenate,Layer, InputSpec, Flatten,Dense, Softmax, Dropout\n",
        "from tensorflow.keras import Model,initializers, regularizers, constraints,Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
        "\n",
        "from JSAnimation import IPython_display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbK098GK_mDp",
        "colab_type": "text"
      },
      "source": [
        "<h1> Tunneling to TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR8_OpWa_q1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "import subprocess\n",
        "import tensorflow as tf\n",
        "\n",
        "__all__ = [\n",
        "  'install_ngrok', \n",
        "  'launch_tensorboard',\n",
        "]\n",
        "\n",
        "def __shell__(cmd, split=True):\n",
        "  # get_ipython().system_raw(cmd)\n",
        "  result = get_ipython().getoutput(cmd, split=split)\n",
        "  if result and not split:\n",
        "    result = result.strip('\\n')\n",
        "  return result\n",
        "\n",
        "def install_ngrok(bin_dir=\"/tmp\"):\n",
        "  TARGET_DIR = bin_dir\n",
        "  CWD = os.getcwd()\n",
        "  is_grok_avail = os.path.isfile(os.path.join(TARGET_DIR,'ngrok'))\n",
        "  if is_grok_avail:\n",
        "    print(\"ngrok installed\")\n",
        "  else:\n",
        "    import platform\n",
        "    plat = platform.platform()\n",
        "    if 'x86_64' in plat:\n",
        "      \n",
        "      os.chdir('/tmp')\n",
        "      print(\"calling wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ...\" )\n",
        "      get_ipython().system_raw( \"wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\" )\n",
        "      print(\"calling unzip ngrok-stable-linux-amd64.zip ...\")\n",
        "      get_ipython().system_raw( \"unzip ngrok-stable-linux-amd64.zip\" )\n",
        "      os.rename(\"ngrok\", \"{}/ngrok\".format(TARGET_DIR))\n",
        "      os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
        "      is_grok_avail = os.path.isfile(os.path.join(TARGET_DIR,'ngrok'))\n",
        "      os.chdir(TARGET_DIR)\n",
        "      if is_grok_avail:\n",
        "        print(\"ngrok installed. path={}\".format(os.path.join(TARGET_DIR,'ngrok')))\n",
        "      else:\n",
        "        raise ValueError( \"ERROR: ngrok not found, path=\".format(TARGET_DIR) )\n",
        "    else:\n",
        "      raise NotImplementedError( \"ERROR, ngrok install not configured for this platform, platform={}\".format(plat))\n",
        "    os.chdir(CWD)\n",
        "    return\n",
        "    \n",
        "def launch_tensorboard(bin_dir=\"/tmp\", log_dir=\"/tmp\", retval=False):\n",
        "  install_ngrok(bin_dir)\n",
        "    \n",
        "  if not tf.gfile.Exists(log_dir):  tf.gfile.MakeDirs(log_dir)\n",
        "  ps = __shell__(\"ps -ax\")\n",
        "  is_tensorboard_running = len([f for f in ps if \"tensorboard\" in f ]) > 0\n",
        "  is_ngrok_running = len([f for f in ps if \"ngrok\" in f ]) > 0\n",
        "  print(\"status: tensorboard={}, ngrok={}\".format(is_tensorboard_running, is_ngrok_running))\n",
        "\n",
        "  if not is_tensorboard_running:\n",
        "    get_ipython().system_raw(\n",
        "        'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "        .format(log_dir)\n",
        "    )\n",
        "    is_tensorboard_running = True\n",
        "    \n",
        "  if not is_ngrok_running:\n",
        "    get_ipython().system_raw('{}/ngrok http 6006 &'.format(bin_dir))\n",
        "    is_ngrok_running = True\n",
        "  import time\n",
        "  time.sleep(3)\n",
        "  retval = requests.get('http://localhost:4040/api/tunnels')\n",
        "  tensorboard_url = retval.json()['tunnels'][0]['public_url'].strip()\n",
        "  print(\"tensorboard url=\", tensorboard_url)\n",
        "  if retval:\n",
        "    return tensorboard_url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7797RzeABBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set paths\n",
        "ROOT = %pwd\n",
        "LOG_DIR = os.path.join(ROOT, 'log1')\n",
        "\n",
        "# will install `ngrok`, if necessary\n",
        "# will create `log_dir` if path does not exist\n",
        "launch_tensorboard( bin_dir=ROOT, log_dir=LOG_DIR )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWf7VF5S99iW",
        "colab_type": "text"
      },
      "source": [
        "<h1> Get Data from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N30wZgH5_nVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## connect to drive and Locally download the file\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "download = drive.CreateFile({'id': '1HLYgLqxFrrWy1Q58knC85jX0PGgLgYeo'})\n",
        "download.GetContentFile('Assignment')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76LO-b_rAv0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ./Assignment -d ./Assignment2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEK-nx2iM9DC",
        "colab_type": "text"
      },
      "source": [
        "<h1> Pre-Preocessing and Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO0TrRna-EMf",
        "colab_type": "text"
      },
      "source": [
        "<h2>Dict having file names</h2>frames[i] contains all the images in lec i <br>and<br> labels[i] has corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsYLGpMOBI8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames_dir = next(os.walk('./Assignment2/frames/'))[1]\n",
        "frames_dir.sort()\n",
        "frames = {}\n",
        "labels = {}\n",
        "for i in range(len(frames_dir)):\n",
        "  a=next(os.walk('./Assignment2/frames/' + frames_dir[i] + '/'))[2]\n",
        "  a.sort()\n",
        "  frames[i] = ['./Assignment2/frames/' + frames_dir[i] + '/' + s for s in a]\n",
        "  labels[i] = np.genfromtxt('./Assignment2/labels/' + frames_dir[i] +'.csv', delimiter=',')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJGqRs-4OI2d",
        "colab_type": "text"
      },
      "source": [
        "<h2>Img --> np array</h2>return size= 240, 320, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MDmI9PHkVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def im(image_address):\n",
        "  img = cv2.imread(image_address)\n",
        "  res = cv2.resize(img, dsize=(320, 240), interpolation=cv2.INTER_CUBIC)\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccPYj7XGTMpK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Total number of initial data points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCGq5AYOTMDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=0\n",
        "for i in labels:\n",
        "  s=s+np.sum(labels[i])\n",
        "print(s)\n",
        "s1=0\n",
        "for i in range(35):\n",
        "  s1=s1+labels[i].shape[0]\n",
        "print(s1)\n",
        "plt.bar([\"zero\",\"one\"],[29137,1130])\n",
        "plt.ylabel(\"Class count in data\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0_X41GA8Yf_",
        "colab_type": "text"
      },
      "source": [
        "<h2>Data Augmentation</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYRmGTEI8Xsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes = {}\n",
        "for i in range(len(frames_dir)):\n",
        "  indexes[i] = []\n",
        "  for j in range(len(labels[i])):\n",
        "    if labels[i][j]==1 and j>1 and j<len(labels[i])-2:\n",
        "      indexes[i].append(j)\n",
        "\n",
        "r={}\n",
        "for i in range(len(frames_dir)):\n",
        "  \n",
        "  r[i] = [[indexes[i][0]-1,indexes[i][0],indexes[i][0]+1]]\n",
        "  r[i].append([indexes[i][0],indexes[i][0]+1,indexes[i][0]+2])\n",
        "\n",
        "  for j in range(1,int(np.sum(labels[i]))-2):\n",
        "    \n",
        "    r[i].append([indexes[i][j]-1,indexes[i][j],indexes[i][j]+1])\n",
        "    r[i].append([indexes[i][j],indexes[i][j]+1,indexes[i][j]+2])\n",
        "    \n",
        "    for k in range(1, int(np.sum(labels[i]))-2):\n",
        "      if j!=k:\n",
        "        r[i].append([indexes[i][j]-1,indexes[i][j],indexes[i][k]+1])\n",
        "        r[i].append([indexes[i][j],indexes[i][k]+1,indexes[i][k]+2])\n",
        "        \n",
        "a0=[]\n",
        "for i in range(35):\n",
        "      a = [random.randint(1,int(labels[i].shape[0]-3)) for k in range(int(len(r[i])*0.21))]\n",
        "      for j in a:\n",
        "        if labels[i][j]==0 and labels[i][j-1]==0:\n",
        "          a0.append([i,j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dKLYMOJHL5W",
        "colab_type": "text"
      },
      "source": [
        "Number of data points after augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrgGmgv8HQ8l",
        "colab_type": "code",
        "outputId": "47429b65-83fe-4b45-ded1-4c45c2db94b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s=0\n",
        "for i in range(35):\n",
        "  s=s+len(r[i])\n",
        "print(\"Label one: \", s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label one:  98200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV-U6MH_gkSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q=[]\n",
        "for i in range(35):\n",
        "  p1=0\n",
        "  p2=0\n",
        "  for j in range(len(labels[i])):\n",
        "    if labels[i][j] == 1:\n",
        "      p1=p2\n",
        "      p2=j\n",
        "      q.append(p2-p1)\n",
        "\n",
        "a = plt.hist(q,230)\n",
        "plt.ylabel(\"Number of occurences in dataset\")\n",
        "plt.xlabel(\"Duration between imp frames\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-q7gQ5qO5g-",
        "colab_type": "text"
      },
      "source": [
        "<h2>Normalize and save in h5py file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my-rZ0NbCByi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('./X.h5','w') as hdf:\n",
        "  z=0\n",
        "  dset = hdf.create_dataset(\"X\", (25000,240 ,320 ,9))\n",
        "  for i in range(35):\n",
        "      a = [random.randint(0,len(r[i])-1) for k in range(int(len(r[i])*0.102))]\n",
        "      for j in a:\n",
        "        dset[z] = np.concatenate([im(frames[i][r[i][j][0]]),im(frames[i][r[i][j][1]]),im(frames[i][r[i][j][2]])], axis=2)/255\n",
        "        z=z+1\n",
        "        if z%1000==0:\n",
        "          print(z)\n",
        "      true_upto = z-1\n",
        "  p=-1\n",
        "  while z<25000:\n",
        "      p=p+1\n",
        "      dset[z] = np.concatenate([im(frames[a0[p][0]][a0[p][1]-1]),im(frames[a0[p][0]][a0[p][1]]),im(frames[a0[p][0]][a0[p][1]+1])], axis=2)/255\n",
        "      z=z+1\n",
        "      if z%1000==0:\n",
        "           print(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahd_0PcByvje",
        "colab_type": "code",
        "outputId": "02070b71-c176-4272-ed2b-c4095a906789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(true_upto)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1SjLQKWu-eR",
        "colab_type": "text"
      },
      "source": [
        "<h1>\n",
        "3D_CNN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcRnnz0HKOGP",
        "colab_type": "text"
      },
      "source": [
        "<h2>Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGvTI1OiJa5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, list_IDs, labels_partition, batch_size=2, shuffle = True):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels_partition\n",
        "        self.list_IDs = list_IDs\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        #'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs)/self.batch_size))\n",
        "      \n",
        "    def __getitem__(self, index):\n",
        "      #'Generate one batch of data'\n",
        "      indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "      \n",
        "      list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "      list_IDs_temp.sort()\n",
        "\n",
        "      with h5py.File('./X.h5','r') as hdf:\n",
        "        X=np.array(hdf['X'][list_IDs_temp,:,:,:])\n",
        "      y = np.zeros((self.batch_size))\n",
        "      for p in range(self.batch_size):\n",
        "          y[p] = self.labels[list_IDs_temp[p]]\n",
        "\n",
        "      \n",
        "      return (np.array([[X[0,:,:,:3],X[0,:,:,3:6],X[0,:,:,6:]],[X[1,:,:,:3],X[1,:,:,3:6],X[1,:,:,6:]],[X[2,:,:,:3],X[2,:,:,3:6],X[2,:,:,6:]],[X[3,:,:,:3],X[3,:,:,3:6],X[3,:,:,6:]]]),y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8PPFZsDzkrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datasets\n",
        "xxx=list(range(25000))\n",
        "random.shuffle(xxx)\n",
        "partition = {\"train\" : xxx[:24000], \"validation\": xxx[24000:]}\n",
        "labels_partition = {}\n",
        "for i in xxx:\n",
        "  if i <10001:\n",
        "    labels_partition[i] = 1\n",
        "  else:\n",
        "    labels_partition[i] = 0\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 4,\n",
        "          'shuffle': True}\n",
        "\n",
        "s0=0\n",
        "s1=0\n",
        "training_generator = DataGenerator(partition['train'], labels_partition, **params)\n",
        "import time\n",
        "start = time.time()\n",
        "for i in range(10):\n",
        "  X0,y0=training_generator[i]\n",
        "  s0=s0+np.sum(y0[:,0])\n",
        "  s1=s1+np.sum(y0[:,1])\n",
        "print(s0,s1)\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbOyK0N01xvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(training_generator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfq0uk4lNw0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X0.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrowJ4SIgoBH",
        "colab_type": "text"
      },
      "source": [
        "<h2>Model</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDCvCrAuKYaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Block(input_layer,\n",
        "           n_filters,\n",
        "           batch_normalization=True,\n",
        "           kernel=(3, 3, 3),\n",
        "           strides=(1,3,3),\n",
        "           dropout_rate=0.4,\n",
        "           data_format=\"channels_first\"):\n",
        "\n",
        "    layer = Conv3D(n_filters, kernel, padding='same', strides=strides)(input_layer)\n",
        "    if batch_normalization:\n",
        "        layer = BatchNormalization()(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),padding='SAME')(layer)\n",
        "    dropout = SpatialDropout3D(rate=dropout_rate, data_format=data_format)(layer)\n",
        "    return dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCbBvFOkT59H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MODEL1(input_shape=(360,450,9),\n",
        "                      n_filter=3,\n",
        "                      depth=3, \n",
        "                      dropout_rate=0.3,\n",
        "                      optimizer=Adam, \n",
        "                      initial_learning_rate=5e-4,\n",
        "                      loss_function=tensorflow.keras.losses.binary_crossentropy):\n",
        "  graph0 = tf.Graph()\n",
        "  with graph0.as_default():\n",
        "    inputs = Input(input_shape)\n",
        "    layer1 = BatchNormalization()(inputs)\n",
        "    for level_number in range(depth):\n",
        "      layer1 = Block(layer1,n_filters=n_filter[level_number])\n",
        "    layer1 = Flatten()(layer1)\n",
        "    dense_1 = Dense(512, activation = 'relu')(layer1)\n",
        "    dense_2 = Dense(10 , activation = 'relu')(dense_1)\n",
        "    activation_block = Dense(1 , activation = 'sigmoid')(dense_2)\n",
        "    model = Model(inputs=inputs, outputs=activation_block)\n",
        "    model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function,metrics = ['accuracy'])\n",
        "    writer = tf.summary.FileWriter(logdir='log1', graph=graph0)\n",
        "    writer.flush()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQc_Jgrgx9xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = MODEL1(input_shape=(3,240,320,3), n_filter=[32,64,128], depth=2, dropout_rate=0.42856,\n",
        "                      optimizer=Adam, initial_learning_rate=0.0001,\n",
        "                      loss_function=tensorflow.keras.losses.binary_crossentropy)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdDEzl58gdjM",
        "colab_type": "text"
      },
      "source": [
        "<h3>Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Bit3lUbN_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_dir_name(initial_learning_rate=0.0001,depth=4,n_filters=5,dropout_rate=0.4,optimizer='Adam',loss_function='dice'):\n",
        "\n",
        "    # The dir-name for the TensorBoard log-dir.\n",
        "    s = \"./log1/lr_{0:.0e}_d_{1}_f_{2}_{3}_o_{4}_l_{5}/\"\n",
        "\n",
        "    log_dir = s.format(initial_learning_rate,\n",
        "                       depth,\n",
        "                       n_filters,\n",
        "                       dropout_rate,\n",
        "                       optimizer,\n",
        "                       loss_function)\n",
        "\n",
        "    return log_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqxpgFq5x83u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datasets\n",
        "xxx=list(range(15000))\n",
        "random.shuffle(xxx)\n",
        "partition = {\"train\" : xxx[:14900], \"validation\": xxx[14900:]}\n",
        "labels_partition = {}\n",
        "for i in xxx:\n",
        "  if i <10001:\n",
        "    labels_partition[i] = 1\n",
        "  else:\n",
        "    labels_partition[i] = 0\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 4,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(partition['train'], labels_partition, **params)\n",
        "validation_generator = DataGenerator(partition['validation'], labels_partition, **params)                                                                                                            \n",
        "\n",
        "cb_1=tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
        "cb_2=tensorflow.keras.callbacks.ModelCheckpoint(filepath='./weights2.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "log_dir = log_dir_name()\n",
        "\n",
        "cb_3 = tensorflow.keras.callbacks.TensorBoard(\n",
        "        log_dir=log_dir,\n",
        "        histogram_freq=0,\n",
        "        write_graph=True,\n",
        "        write_grads=False,\n",
        "        write_images=False)\n",
        "\n",
        "# results = model.fit(x = ,y = ,batch_size=batch_size, epochs=5, verbose=1, callbacks=[cb_1,cb_2,cb_3], validation_split=0.02, shuffle=True)\n",
        "\n",
        "results = model.fit_generator(generator=training_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                   epochs=50,\n",
        "                   callbacks=[cb_1,cb_2,cb_3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjmQuCiDf5c2",
        "colab_type": "text"
      },
      "source": [
        "<h2>Testing MODEL</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUSmnRnQHGD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.predict(validation_generator[2]))\n",
        "print(validation_generator[2][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwPPFbamRAMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_generator = DataGenerator(partition['validation'], labels_partition, **params)\n",
        "prediction = model.predict_generator(generator=validation_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_NvGIX8gEpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(prediction[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FzwJGP4n18o",
        "colab_type": "text"
      },
      "source": [
        "<h1>A time-distributed ConvNet and passing the features to an RNN, in one network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzqFRz-StUzQ",
        "colab_type": "text"
      },
      "source": [
        "<h2>Soft Label Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWWhspMhtY2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soft_labels = {}\n",
        "for i in range(35):\n",
        "  previous = -10\n",
        "  soft = np.zeros(labels[i].shape[0])\n",
        "  for j in reversed(range(labels[i].shape[0])):\n",
        "    if (labels[i][j]==1):\n",
        "      previous = j\n",
        "    soft[j] = np.exp(-1 * np.square(j - previous)/(2*2))\n",
        "  soft_labels[i] = soft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YPgs6dY2yeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c=soft_labels[0][:100]\n",
        "c=np.flip(c,axis=0)\n",
        "plt.plot(range(100),c)\n",
        "plt.ylabel(\"Label value\")\n",
        "plt.xlabel(\"frame no.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPg5XTA-2vIs",
        "colab_type": "text"
      },
      "source": [
        "<h2>Data Generator</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jWgUj-P2zR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator1(tensorflow.keras.utils.Sequence):\n",
        "  \n",
        "    def __init__(self, list_IDs, labels_partition, batch_size=2, shuffle = True):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels_partition\n",
        "        self.list_IDs = list_IDs\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        #'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs)/self.batch_size))\n",
        "      \n",
        "    def __getitem__(self, index):\n",
        "      #'Generate one batch of data'\n",
        "      indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "      \n",
        "      list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "      list_IDs_temp.sort()\n",
        "\n",
        "      with h5py.File('./X.h5','r') as hdf:\n",
        "        X=np.array(hdf['X'][list_IDs_temp,:,:,:])\n",
        "      y = np.zeros((self.batch_size,2))\n",
        "      for p in range(self.batch_size):\n",
        "          y[p][0] = self.labels[list_IDs_temp[p]]\n",
        "      y[:,1] = 1-y[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2cic79ZtbyB",
        "colab_type": "text"
      },
      "source": [
        "<h2>Model</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLMeGXjXsFar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lrcn(input_shape = (16,240,320,3),\n",
        "         optimizer = Adam,\n",
        "         loss_function = tensorflow.keras.losses.binary_crossentropy, \n",
        "         initial_learning_rate = 0.0001):  \n",
        "#     graph = tf.Graph()\n",
        "#     with graph.as_default():\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(64, (7, 7), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
        "        model.add(TimeDistributed(Conv2D(64, (3,3), kernel_initializer=\"he_normal\", activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Bidirectional(LSTM(256, return_sequences=True, dropout=0.5)))\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function,metrics = ['accuracy'])\n",
        "#     writer = tf.summary.FileWriter(logdir='log1', graph=graph)\n",
        "#     writer.flush()    \n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfUA0eXgVRsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lrcn()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAWh0y1othu8",
        "colab_type": "text"
      },
      "source": [
        "<h2>Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dMe-2dStk3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "for i in range(1):\n",
        "  x_train=[]\n",
        "  y_train=[]\n",
        "  for t in tqdm(range(4)):\n",
        "    for j in range(int(len(frames[i])//16)):\n",
        "      x=[]\n",
        "      y=[]\n",
        "      for k in range(16):\n",
        "        image = im(frames[i*4+t][j*16+k])\n",
        "        x.append((image - image.mean()) / image.std())\n",
        "        y.append(soft_labels[i*4+t][j*16+k])\n",
        "      x_train.append(np.array(x))\n",
        "      y_train.append(np.array(y))\n",
        "  X_train.append(np.array(x_train))\n",
        "  Y_train.append(np.array(y_train))\n",
        "model.fit(X_train,Y_train,batch_size=4,epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4xk7EyQM_Ax",
        "colab_type": "code",
        "outputId": "2d560c05-180d-4a8a-9c00-c50db32cdaa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(x_train))\n",
        "print(x_train[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4150\n",
            "(240, 320, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm2_YMcrn9Wh",
        "colab_type": "text"
      },
      "source": [
        "<h1> Model 3\n",
        "Extracting features from each frame with a ConvNet(inception net) and passing the sequence to a separate RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F18OX8x1qnrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm(input_shape = (None,4096),\n",
        "         initial_learning_rate=0.0001,\n",
        "         optimizer=Adam,\n",
        "        loss_function=tensorflow.keras.losses.binary_crossentropy):\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(2048, return_sequences=True,\n",
        "                       input_shape=input_shape,\n",
        "                       dropout=0.5))\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function,metrics = ['accuracy'])\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJCVQuKRtFI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lstm()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WAh8U2Gs5Nw",
        "colab_type": "text"
      },
      "source": [
        "<h1>2D cnn with 3 stacked frames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfDA6EF_s4an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Block(input_layer,\n",
        "           n_filters,\n",
        "           batch_normalization=True,\n",
        "           kernel=(3, 3),\n",
        "           dropout_rate=0.4,\n",
        "           data_format=\"channels_first\"):\n",
        "\n",
        "    layer = Conv2D(n_filters, kernel, padding='same')(input_layer)\n",
        "    if batch_normalization:\n",
        "        layer = BatchNormalization()(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding='SAME')(layer)\n",
        "    dropout = SpatialDropout2D(rate=dropout_rate, data_format=data_format)(layer)\n",
        "    return dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCcGzZ1MyP5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MODEL1(input_shape=(360,450,9),\n",
        "                      n_filter=3,\n",
        "                      depth=3, \n",
        "                      dropout_rate=0.3,\n",
        "                      optimizer=Adam, \n",
        "                      initial_learning_rate=5e-4,\n",
        "                      loss_function=tensorflow.keras.losses.binary_crossentropy):\n",
        "  graph0 = tf.Graph()\n",
        "  with graph0.as_default():\n",
        "    inputs = Input(input_shape)\n",
        "    layer1 = BatchNormalization()(inputs)\n",
        "    for level_number in range(depth):\n",
        "      layer1 = Block(layer1,n_filters=n_filter[level_number])\n",
        "    layer1 = Flatten()(layer1)\n",
        "    dense_1 = Dense(512, activation = 'relu')(layer1)\n",
        "    dense_2 = Dense(10 , activation = 'relu')(dense_1)\n",
        "    activation_block = Dense(1 , activation = 'sigmoid')(dense_2)\n",
        "    model = Model(inputs=inputs, outputs=activation_block)\n",
        "    model.compile(optimizer=optimizer(lr=initial_learning_rate), loss=loss_function,metrics = ['accuracy'])\n",
        "  writer = tf.summary.FileWriter(logdir='log1', graph=graph0)\n",
        "  writer.flush()\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjiTMPjayV38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MODEL1(input_shape=(240,320,9), n_filter=[32,64,128,256,125], depth=5, dropout_rate=0.42856,\n",
        "                      optimizer=Adam, initial_learning_rate=0.0001,\n",
        "                      loss_function=tensorflow.keras.losses.binary_crossentropy)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}