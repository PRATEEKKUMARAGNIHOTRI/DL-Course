{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ruuuUNTguYp"
   },
   "source": [
    "# Initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbCigZtNZZgl"
   },
   "source": [
    "## Import and Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7387,
     "status": "ok",
     "timestamp": 1557157888106,
     "user": {
      "displayName": "Prateek Kumar Agnihotri",
      "photoUrl": "https://lh5.googleusercontent.com/-Mv0WJR5Cz3w/AAAAAAAAAAI/AAAAAAAAAJ8/SnyQ34rsQog/s64/photo.jpg",
      "userId": "17111782266645352091"
     },
     "user_tz": -330
    },
    "id": "d44TznbgZZgm",
    "outputId": "b5b41fad-55ac-47e9-c76c-72aba3b960c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as k\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWORMSC8FDR4"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7110,
     "status": "ok",
     "timestamp": 1557157888660,
     "user": {
      "displayName": "Prateek Kumar Agnihotri",
      "photoUrl": "https://lh5.googleusercontent.com/-Mv0WJR5Cz3w/AAAAAAAAAAI/AAAAAAAAAJ8/SnyQ34rsQog/s64/photo.jpg",
      "userId": "17111782266645352091"
     },
     "user_tz": -330
    },
    "id": "aFe4wHGRFKle",
    "outputId": "7bd0f9d0-ea0c-4b3e-a58e-3aa69bc8bc51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9df674a6d8>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "\n",
    "img_index = 5\n",
    "\n",
    "label_index = y_train[img_index]\n",
    "\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zx-Ee6LHZZgt"
   },
   "source": [
    "## Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNh5NIckZZgu"
   },
   "outputs": [],
   "source": [
    "w, h = 28, 28\n",
    "num_classes = 10\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5897,
     "status": "ok",
     "timestamp": 1557157888681,
     "user": {
      "displayName": "Prateek Kumar Agnihotri",
      "photoUrl": "https://lh5.googleusercontent.com/-Mv0WJR5Cz3w/AAAAAAAAAAI/AAAAAAAAAJ8/SnyQ34rsQog/s64/photo.jpg",
      "userId": "17111782266645352091"
     },
     "user_tz": -330
    },
    "id": "LMSg53fiZZgx",
    "outputId": "caa33e7c-ece1-4b1b-e4ef-66b4ebadfef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data - 60000\n",
      "Number of test data - 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train data - \" + str(len(x_train)))\n",
    "print(\"Number of test data - \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7tjL616SglbR"
   },
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhalcO03ZZg3"
   },
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdF98vwEfGI-"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "model_name = 'fmnist_model'\n",
    "save_dir = '/model/' + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1557162220193,
     "user": {
      "displayName": "Prateek Kumar Agnihotri",
      "photoUrl": "https://lh5.googleusercontent.com/-Mv0WJR5Cz3w/AAAAAAAAAAI/AAAAAAAAAJ8/SnyQ34rsQog/s64/photo.jpg",
      "userId": "17111782266645352091"
     },
     "user_tz": -330
    },
    "id": "QgTZ47SsZZg4",
    "outputId": "72ee427d-c225-40eb-a5e9-010919d9966a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 128)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 839,114\n",
      "Trainable params: 839,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQUlOa8cZZg9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtOvh3YVZZg_"
   },
   "source": [
    "## Train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTmapAttZZhA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model_fmnist.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True,\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-MGLwZQy05d"
   },
   "source": [
    "## Load Model with the best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD1tecxUZZhE"
   },
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model.load_weights('model_fmnist.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RTRkan4yq5H"
   },
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1557120278226,
     "user": {
      "displayName": "Prateek Kumar Agnihotri",
      "photoUrl": "https://lh5.googleusercontent.com/-Mv0WJR5Cz3w/AAAAAAAAAAI/AAAAAAAAAJ8/SnyQ34rsQog/s64/photo.jpg",
      "userId": "17111782266645352091"
     },
     "user_tz": -330
    },
    "id": "VZtqBqFFy62R",
    "outputId": "8cab18cd-cc74-4aad-f121-0b7d1b499971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2190603072106838\n",
      "\n",
      " Test accuracy: 0.9263\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJv7XEk10bOv"
   },
   "source": [
    "## Visualize prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwNmlfIC0YxM"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "\n",
    "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(x_test[index]))\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(y_test[index])\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
    "                                  fashion_mnist_labels[true_index]),\n",
    "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjguP2xdqSl3"
   },
   "source": [
    "# Lipchitz Constrained Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tH74-pcn_Wvq"
   },
   "source": [
    "### Outputs of Pre-final layer (i.e. just before softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCqQLfbn_cMP"
   },
   "outputs": [],
   "source": [
    "get_9th_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[9].output])\n",
    "layer_output = get_9th_layer_output([x_train])[0]\n",
    "np.save(\"output.npy\", layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCukKZXt9wWH"
   },
   "source": [
    "### A custom layer to apply Lipscitz Constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XrOX8jH8zSe"
   },
   "outputs": [],
   "source": [
    "class SpectralDecay(Regularizer):\n",
    "    \n",
    "    def __init__(self, sd_lambda, iterations=2):\n",
    "        self.sd_lambda = sd_lambda\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        if self.sd_lambda == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            w = K.reshape(w, [-1, w.shape.as_list()[-1]])\n",
    "            x = K.random_normal_variable(shape=(int(w.shape[1]), 1), mean=0, scale=1)\n",
    "\n",
    "            for i in range(0, self.iterations): \n",
    "                x_p = K.dot(w, x)\n",
    "                x = K.dot(K.transpose(w), x_p)\n",
    "            \n",
    "            return self.sd_lambda * K.sum(K.pow(K.dot(w, x), 2.0)) / K.sum(K.pow(x, 2.0))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"sd_lambda\": self.sd_lambda,\n",
    "            \"iterations\": self.iterations\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sR7b231C99P2"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abqAc6-A86M8"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "model_name = 'fmnist_model'\n",
    "save_dir = '/model/' + model_name\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(SpectralDecay())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(SpectralDecay())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(SpectralDecay())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAWJJNth9_eK"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBzMoofH-Bm-"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam'\n",
    "             )\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model_fmnist.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "model.fit(x_train,layer_output ,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True,\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlkB1YDxgiGi"
   },
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQUkZsXqhcKP"
   },
   "source": [
    "##FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tph5CxunL7zU"
   },
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "# Initialize adversarial example with input image\n",
    "x_adv = x_train[100]\n",
    "# Added noise\n",
    "x_noise = np.zeros_like(x)\n",
    "\n",
    "# Choose target class\n",
    "epsilon = 0.1\n",
    "target_class = 0 \n",
    "prev_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UL1cFQrboimk"
   },
   "outputs": [],
   "source": [
    "step_size = 0.05\n",
    "\n",
    "target = K.one_hot(target_class, 10)\n",
    "\n",
    "loss = -1*K.categorical_crossentropy(target, model.output)\n",
    "\n",
    "grads = K.gradients(loss, model.input)\n",
    "\n",
    "delta = K.sign(grads[0])\n",
    "\n",
    "x_noise = x_noise + delta\n",
    "\n",
    "\n",
    "x_adv = x_adv + epsilon*delta\n",
    "\n",
    "# Get the new image and predictions\n",
    "x_adv = sess.run(x_adv, feed_dict={model.input:x})\n",
    "preds = model.predict(x_adv)\n",
    "\n",
    "Ad_img = image + noise\n",
    "Ad_img = np.clip(a=noisy_img, a_min=0.0, a_max=1.0)\n",
    "gradients = k.gradients(loss, noise)\n",
    "noise -= step_size*gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwkJpRtahgiN"
   },
   "source": [
    "## Carlini-Wagner Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvkviqSThkBW"
   },
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 1000   \n",
    "ABORT_EARLY = True      \n",
    "LEARNING_RATE = 1e-2    \n",
    "INITIAL_CONST = 1e-3    \n",
    "LARGEST_CONST = 2e6     \n",
    "REDUCE_CONST = False    \n",
    "TARGETED = True         \n",
    "CONST_FACTOR = 2.0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITpadOKdPM_L"
   },
   "outputs": [],
   "source": [
    "class CarliniL0:\n",
    "    def __init__(self, sess, model,\n",
    "                 targeted = TARGETED, learning_rate = LEARNING_RATE,\n",
    "                 max_iterations = MAX_ITERATIONS, abort_early = ABORT_EARLY,\n",
    "                 initial_const = INITIAL_CONST, largest_const = LARGEST_CONST,\n",
    "                 reduce_const = REDUCE_CONST, const_factor = CONST_FACTOR,\n",
    "                 independent_channels = False):\n",
    "        self.model = model\n",
    "        self.sess = sess\n",
    "\n",
    "        self.TARGETED = targeted\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.MAX_ITERATIONS = max_iterations\n",
    "        self.ABORT_EARLY = abort_early\n",
    "        self.INITIAL_CONST = initial_const\n",
    "        self.LARGEST_CONST = largest_const\n",
    "        self.REDUCE_CONST = reduce_const\n",
    "        self.const_factor = const_factor\n",
    "        self.independent_channels = independent_channels\n",
    "\n",
    "        self.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK = False\n",
    "\n",
    "        self.grad = self.gradient_descent(sess, model)\n",
    "\n",
    "    def gradient_descent(self, sess, model):\n",
    "        def compare(x,y):\n",
    "            if self.TARGETED:\n",
    "                return x == y\n",
    "            else:\n",
    "                return x != y\n",
    "        shape = (1,model.image_size,model.image_size,model.num_channels)\n",
    "        \n",
    "        # the variable to optimize over\n",
    "        modifier = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "\n",
    "        # the variables we're going to hold, use for efficiency\n",
    "        canchange = tf.Variable(np.zeros(shape),dtype=np.float32)\n",
    "        simg = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "        original = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "        timg = tf.Variable(np.zeros(shape,dtype=np.float32))\n",
    "        tlab = tf.Variable(np.zeros((1,model.num_labels),dtype=np.float32))\n",
    "        const = tf.placeholder(tf.float32, [])\n",
    "\n",
    "        # and the assignment to set the variables\n",
    "        assign_modifier = tf.placeholder(np.float32,shape)\n",
    "        assign_canchange = tf.placeholder(np.float32,shape)\n",
    "        assign_simg = tf.placeholder(np.float32,shape)\n",
    "        assign_original = tf.placeholder(np.float32,shape)\n",
    "        assign_timg = tf.placeholder(np.float32,shape)\n",
    "        assign_tlab = tf.placeholder(np.float32,(1,self.model.num_labels))\n",
    "\n",
    "        # these are the variables to initialize when we run\n",
    "        set_modifier = tf.assign(modifier, assign_modifier)\n",
    "        setup = []\n",
    "        setup.append(tf.assign(canchange, assign_canchange))\n",
    "        setup.append(tf.assign(timg, assign_timg))\n",
    "        setup.append(tf.assign(original, assign_original))\n",
    "        setup.append(tf.assign(simg, assign_simg))\n",
    "        setup.append(tf.assign(tlab, assign_tlab))\n",
    "        \n",
    "        newimg = (tf.tanh(modifier + simg)/2)*canchange+(1-canchange)*original\n",
    "        \n",
    "        output = model.predict(newimg)\n",
    "        \n",
    "        real = tf.reduce_sum((tlab)*output,1)\n",
    "        other = tf.reduce_max((1-tlab)*output - (tlab*10000),1)\n",
    "        if self.TARGETED:\n",
    "            # if targetted, optimize for making the other class most likely\n",
    "            loss1 = tf.maximum(0.0, other-real+.01)\n",
    "        else:\n",
    "            # if untargeted, optimize for making this class least likely.\n",
    "            loss1 = tf.maximum(0.0, real-other+.01)\n",
    "            \n",
    "        loss2 = tf.reduce_sum(tf.square(newimg-tf.tanh(timg)/2))\n",
    "        loss = const*loss1+loss2\n",
    "            \n",
    "        outgrad = tf.gradients(loss, [modifier])[0]\n",
    "        \n",
    "        # setup the adam optimizer and keep track of variables we're creating\n",
    "        start_vars = set(x.name for x in tf.global_variables())\n",
    "        optimizer = tf.train.AdamOptimizer(self.LEARNING_RATE)\n",
    "        train = optimizer.minimize(loss, var_list=[modifier])\n",
    "\n",
    "        end_vars = tf.global_variables()\n",
    "        new_vars = [x for x in end_vars if x.name not in start_vars]\n",
    "        init = tf.variables_initializer(var_list=[modifier,canchange,simg,\n",
    "                                                  original,timg,tlab]+new_vars)\n",
    "\n",
    "        \n",
    "        def doit(oimgs, labs, starts, valid, CONST):\n",
    "            # convert to tanh-space\n",
    "            imgs = np.arctanh(np.array(oimgs)*1.999999)\n",
    "            starts = np.arctanh(np.array(starts)*1.999999)\n",
    "\n",
    "            # initialize the variables\n",
    "            sess.run(init)\n",
    "            sess.run(setup, {assign_timg: imgs, \n",
    "                                    assign_tlab:labs, \n",
    "                                    assign_simg: starts, \n",
    "                                    assign_original: oimgs,\n",
    "                                    assign_canchange: valid})\n",
    "\n",
    "            while CONST < self.LARGEST_CONST:\n",
    "                # try solving for each value of the constant\n",
    "                print('try const', CONST)\n",
    "                for step in range(self.MAX_ITERATIONS):\n",
    "                    feed_dict={const: CONST}\n",
    "                    \n",
    "            # remember the old value\n",
    "                    oldmodifier = self.sess.run(modifier)\n",
    "\n",
    "                    if step%(self.MAX_ITERATIONS//10) == 0:\n",
    "                        print(step,*sess.run((loss1,loss2),feed_dict=feed_dict))\n",
    "\n",
    "                    # perform the update step\n",
    "                    _, works, scores = sess.run([train, loss1, output], feed_dict=feed_dict)\n",
    "\n",
    "                    if np.all(scores>=-.0001) and np.all(scores <= 1.0001):\n",
    "                        if np.allclose(np.sum(scores,axis=1), 1.0, atol=1e-3):\n",
    "                            if not self.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK:\n",
    "                                raise Exception(\"The output of model.predict should return the pre-softmax layer. It looks like you are returning the probability vector (post-softmax). If you are sure you want to do that, set attack.I_KNOW_WHAT_I_AM_DOING_AND_WANT_TO_OVERRIDE_THE_PRESOFTMAX_CHECK = True\")\n",
    "                    \n",
    "                    if works < .0001 and self.ABORT_EARLY:\n",
    "                        # it worked previously, restore the old value and finish\n",
    "                        self.sess.run(set_modifier, {assign_modifier: oldmodifier})\n",
    "                        grads, scores, nimg = sess.run((outgrad, output,newimg),\n",
    "                                                       feed_dict=feed_dict)\n",
    "\n",
    "                        l2s=np.square(nimg-np.tanh(imgs)/2).sum(axis=(1,2,3))\n",
    "                        return grads, scores, nimg, CONST\n",
    "\n",
    "                # we didn't succeed, increase constant and try again\n",
    "                CONST *= self.const_factor\n",
    "        return doit\n",
    "        \n",
    "    def attack(self, imgs, targets):\n",
    "        r = []\n",
    "        for i,(img,target) in enumerate(zip(imgs, targets)):\n",
    "            print(\"Attack iteration\",i)\n",
    "            r.extend(self.attack_single(img, target))\n",
    "        return np.array(r)\n",
    "\n",
    "    def attack_single(self, img, target):\n",
    "        \"\"\"\n",
    "        Run the attack on a single image and label\n",
    "        \"\"\"\n",
    "\n",
    "        # the pixels we can change\n",
    "        valid = np.ones((1,self.model.image_size,self.model.image_size,self.model.num_channels))\n",
    "\n",
    "        # the previous image\n",
    "        prev = np.copy(img).reshape((1,self.model.image_size,self.model.image_size,\n",
    "                                     self.model.num_channels))\n",
    "\n",
    "        # initially set the solution to None, if we can't find an adversarial\n",
    "        # example then we will return None as the solution.\n",
    "        last_solution = None\n",
    "        const = self.INITIAL_CONST\n",
    "\n",
    "        equal_count = None\n",
    "    \n",
    "        while True:\n",
    "            # try to solve given this valid map\n",
    "            res = self.grad([np.copy(img)], [target], np.copy(prev), \n",
    "                       valid, const)\n",
    "            if res == None:\n",
    "                # the attack failed, we return this as our final answer\n",
    "                print(\"Final answer\",equal_count)\n",
    "                return last_solution\n",
    "    \n",
    "            # the attack succeeded, now we pick new pixels to set to 0\n",
    "            restarted = False\n",
    "            gradientnorm, scores, nimg, const = res\n",
    "            if self.REDUCE_CONST: const /= 2\n",
    "    \n",
    "            equal_count = self.model.image_size**2-np.sum(np.all(np.abs(img-nimg[0])<.0001,axis=2))\n",
    "            print(\"Forced equal:\",np.sum(1-valid),\n",
    "                  \"Equal count:\",equal_count)\n",
    "            if np.sum(valid) == 0:\n",
    "                # if no pixels changed, return \n",
    "                return [img]\n",
    "    \n",
    "            if self.independent_channels:\n",
    "                # we are allowed to change each channel independently\n",
    "                valid = valid.flatten()\n",
    "                totalchange = abs(nimg[0]-img)*np.abs(gradientnorm[0])\n",
    "            else:\n",
    "                # we care only about which pixels change, not channels independently\n",
    "                # compute total change as sum of change for each channel\n",
    "                valid = valid.reshape((self.model.image_size**2,self.model.num_channels))\n",
    "                totalchange = abs(np.sum(nimg[0]-img,axis=2))*np.sum(np.abs(gradientnorm[0]),axis=2)\n",
    "            totalchange = totalchange.flatten()\n",
    "\n",
    "            # set some of the pixels to 0 depending on their total change\n",
    "            did = 0\n",
    "            for e in np.argsort(totalchange):\n",
    "                if np.all(valid[e]):\n",
    "                    did += 1\n",
    "                    valid[e] = 0\n",
    "\n",
    "                    if totalchange[e] > .01:\n",
    "                        # if this pixel changed a lot, skip\n",
    "                        break\n",
    "                    if did >= .3*equal_count**.5:\n",
    "                        # if we changed too many pixels, skip\n",
    "                        break\n",
    "\n",
    "            valid = np.reshape(valid,(1,self.model.image_size,self.model.image_size,-1))\n",
    "            print(\"Now forced equal:\",np.sum(1-valid))\n",
    "    \n",
    "            last_solution = prev = nimg"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "_ruuuUNTguYp",
    "LbCigZtNZZgl",
    "tWORMSC8FDR4",
    "Zx-Ee6LHZZgt",
    "7tjL616SglbR",
    "HhalcO03ZZg3",
    "DtOvh3YVZZg_",
    "e-MGLwZQy05d",
    "9RTRkan4yq5H",
    "kjguP2xdqSl3",
    "tH74-pcn_Wvq",
    "hCukKZXt9wWH",
    "sR7b231C99P2",
    "KAWJJNth9_eK",
    "DlkB1YDxgiGi",
    "xQUkZsXqhcKP",
    "WwkJpRtahgiN"
   ],
   "name": "Fashion_Mnist_Classifier.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb",
     "timestamp": 1557070158896
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
